{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3b0bea39-2277-4caa-87cf-9ee348686379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\2624536934.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table = pd.read_html(str(table))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\2624536934.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table = pd.read_html(str(table))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\2624536934.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table = pd.read_html(str(table))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\2624536934.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table = pd.read_html(str(table))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\2624536934.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table = pd.read_html(str(table))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\2624536934.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table = pd.read_html(str(table))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\2624536934.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table = pd.read_html(str(table))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\2624536934.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table = pd.read_html(str(table))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\2624536934.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table = pd.read_html(str(table))\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = 0\n",
    "\n",
    "for page in range(1,10):\n",
    "    url = f'https://finance.naver.com/research/company_list.naver?&page={page}'\n",
    "    fils = [s['href'] for s in soup.select('td.file a')]\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    # table = (soup.select('table'))\n",
    "    table = (soup.select('table'))[0]\n",
    "    table = pd.read_html(str(table))\n",
    "    table = table[0].dropna(how='all') #non값 제거\n",
    "    table['첨부']=fils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fbcf796f-ccb9-428e-bccb-8e83e0dd26b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://stock.pstatic.net/stock-research/company/16/20240520_company_538356000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/16/20240520_company_875397000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/1/20240520_company_150423000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/1/20240520_company_537416000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/18/20240520_company_204626000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/2/20240520_company_318008000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/2/20240520_company_584492000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/29/20240520_company_71276000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/50/20240521_company_333643000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/29/20240520_company_816668000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/63/20240520_company_623228000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/50/20240520_company_723077000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/64/20240520_company_381601000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/50/20240520_company_45359000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/63/20240520_company_656925000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/63/20240520_company_999884000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/63/20240520_company_316397000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/63/20240520_company_611553000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/21/20240520_company_272408000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/63/20240520_company_223631000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/1/20240520_company_67303000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/21/20240520_company_142637000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/21/20240520_company_775875000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/1/20240520_company_843804000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/40/20240520_company_548655000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/40/20240520_company_143103000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/74/20240520_company_526730000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/66/20240517_company_167892000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/66/20240517_company_558705000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/34/20240517_company_733284000.pdf']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1688ab30-0bce-45b1-b81c-5657064bd6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://stock.pstatic.net/stock-research/company/16/20240520_company_538356000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/16/20240520_company_875397000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/1/20240520_company_150423000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/1/20240520_company_537416000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/18/20240520_company_204626000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/2/20240520_company_318008000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/2/20240520_company_584492000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/29/20240520_company_71276000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/50/20240521_company_333643000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/29/20240520_company_816668000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/63/20240520_company_623228000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/50/20240520_company_723077000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/64/20240520_company_381601000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/50/20240520_company_45359000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/63/20240520_company_656925000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/63/20240520_company_999884000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/63/20240520_company_316397000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/63/20240520_company_611553000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/21/20240520_company_272408000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/63/20240520_company_223631000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/1/20240520_company_67303000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/21/20240520_company_142637000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/21/20240520_company_775875000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/1/20240520_company_843804000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/40/20240520_company_548655000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/40/20240520_company_143103000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/74/20240520_company_526730000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/66/20240517_company_167892000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/66/20240517_company_558705000.pdf',\n",
       " 'https://stock.pstatic.net/stock-research/company/34/20240517_company_733284000.pdf']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a63002f0-336a-4f8a-9f9e-bc48697e1e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\63040806.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\63040806.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\63040806.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\63040806.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\63040806.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\63040806.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\63040806.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\63040806.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\63040806.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# 결과를 저장할 DataFrame 초기화\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# 페이지 범위를 설정\n",
    "for page in range(1, 10):\n",
    "    url = f'https://finance.naver.com/research/company_list.naver?&page={page}'\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # 첨부 파일 링크 추출\n",
    "    fils = [s['href'] for s in soup.select('td.file a')]\n",
    "    \n",
    "    # 테이블 추출\n",
    "    table = soup.select('table')[0]\n",
    "    table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
    "    table_df['첨부'] = fils\n",
    "    \n",
    "    # 페이지 결과를 누적\n",
    "    result_df = pd.concat([result_df, table_df], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "545d282d-a63f-4e9b-b483-2fe355925a51",
   "metadata": {},
   "source": [
    "fils"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b71f5c08-c323-4e32-b305-4bf62b80facb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4602e4b1-056e-400e-aa96-77d6e7637abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# 결과를 저장할 DataFrame 초기화\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# 페이지 범위를 설정\n",
    "for page in range(1, 20):\n",
    "    url = f'https://finance.naver.com/research/company_list.naver?&page={page}'\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # 첨부 파일 링크 추출\n",
    "    fils = [s['href'] for s in soup.select('td.file a')]\n",
    "\n",
    "    \n",
    "    # 테이블 추출\n",
    "    table = soup.select('table')[0]\n",
    "    table_html = str(table)\n",
    "    table_df = pd.read_html(StringIO(table_html))[0].dropna(how='all')  # NaN값 제거\n",
    "    table_df['첨부'] = fils\n",
    "    \n",
    "    # 페이지 결과를 누적\n",
    "    result_df = pd.concat([result_df, table_df], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "aacfbf70-3a5d-4887-92ac-6c6fdf5a8fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목명</th>\n",
       "      <th>제목</th>\n",
       "      <th>증권사</th>\n",
       "      <th>첨부</th>\n",
       "      <th>작성일</th>\n",
       "      <th>조회수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>자이에스앤디</td>\n",
       "      <td>조금 다른 이익 감소</td>\n",
       "      <td>교보증권</td>\n",
       "      <td>https://stock.pstatic.net/stock-research/compa...</td>\n",
       "      <td>24.05.31</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HL D&amp;I</td>\n",
       "      <td>성공적인 자체 사업 준공</td>\n",
       "      <td>교보증권</td>\n",
       "      <td>https://stock.pstatic.net/stock-research/compa...</td>\n",
       "      <td>24.05.31</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>휴메딕스</td>\n",
       "      <td>이렇게 성장하는데 이렇게 싸다고?</td>\n",
       "      <td>교보증권</td>\n",
       "      <td>https://stock.pstatic.net/stock-research/compa...</td>\n",
       "      <td>24.05.31</td>\n",
       "      <td>622.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>셀트리온</td>\n",
       "      <td>25년부터 이익의 레벨이 달라진다</td>\n",
       "      <td>하나증권</td>\n",
       "      <td>https://stock.pstatic.net/stock-research/compa...</td>\n",
       "      <td>24.05.31</td>\n",
       "      <td>772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>두올</td>\n",
       "      <td>자기주식 소각을 통한 주주가치 제고</td>\n",
       "      <td>하나증권</td>\n",
       "      <td>https://stock.pstatic.net/stock-research/compa...</td>\n",
       "      <td>24.05.31</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>펄어비스</td>\n",
       "      <td>게임스컴 모멘텀 구간</td>\n",
       "      <td>미래에셋증권</td>\n",
       "      <td>https://ssl.pstatic.net/imgstock/upload/resear...</td>\n",
       "      <td>24.05.13</td>\n",
       "      <td>550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>롯데케미칼</td>\n",
       "      <td>이어지는 개선세, 밸류에이션 매력 부각</td>\n",
       "      <td>한화투자증권</td>\n",
       "      <td>https://ssl.pstatic.net/imgstock/upload/resear...</td>\n",
       "      <td>24.05.10</td>\n",
       "      <td>3612.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>GS리테일</td>\n",
       "      <td>1Q24 Review : 편의점 내 상대적 매력 부각</td>\n",
       "      <td>한화투자증권</td>\n",
       "      <td>https://ssl.pstatic.net/imgstock/upload/resear...</td>\n",
       "      <td>24.05.10</td>\n",
       "      <td>1611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>현대백화점</td>\n",
       "      <td>1Q24 Review : 지누스는 본질이 아닙니다</td>\n",
       "      <td>한화투자증권</td>\n",
       "      <td>https://ssl.pstatic.net/imgstock/upload/resear...</td>\n",
       "      <td>24.05.10</td>\n",
       "      <td>1249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>롯데쇼핑</td>\n",
       "      <td>1Q24 Review : 해외 사업 성과에 대해 프라이..</td>\n",
       "      <td>한화투자증권</td>\n",
       "      <td>https://ssl.pstatic.net/imgstock/upload/resear...</td>\n",
       "      <td>24.05.10</td>\n",
       "      <td>1042.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        종목명                                제목     증권사  \\\n",
       "0    자이에스앤디                       조금 다른 이익 감소    교보증권   \n",
       "1    HL D&I                     성공적인 자체 사업 준공    교보증권   \n",
       "2      휴메딕스                이렇게 성장하는데 이렇게 싸다고?    교보증권   \n",
       "3      셀트리온                25년부터 이익의 레벨이 달라진다    하나증권   \n",
       "4        두올               자기주식 소각을 통한 주주가치 제고    하나증권   \n",
       "..      ...                               ...     ...   \n",
       "565    펄어비스                       게임스컴 모멘텀 구간  미래에셋증권   \n",
       "566   롯데케미칼             이어지는 개선세, 밸류에이션 매력 부각  한화투자증권   \n",
       "567   GS리테일     1Q24 Review : 편의점 내 상대적 매력 부각  한화투자증권   \n",
       "568   현대백화점       1Q24 Review : 지누스는 본질이 아닙니다  한화투자증권   \n",
       "569    롯데쇼핑  1Q24 Review : 해외 사업 성과에 대해 프라이..  한화투자증권   \n",
       "\n",
       "                                                    첨부       작성일     조회수  \n",
       "0    https://stock.pstatic.net/stock-research/compa...  24.05.31   338.0  \n",
       "1    https://stock.pstatic.net/stock-research/compa...  24.05.31   244.0  \n",
       "2    https://stock.pstatic.net/stock-research/compa...  24.05.31   622.0  \n",
       "3    https://stock.pstatic.net/stock-research/compa...  24.05.31   772.0  \n",
       "4    https://stock.pstatic.net/stock-research/compa...  24.05.31   278.0  \n",
       "..                                                 ...       ...     ...  \n",
       "565  https://ssl.pstatic.net/imgstock/upload/resear...  24.05.13   550.0  \n",
       "566  https://ssl.pstatic.net/imgstock/upload/resear...  24.05.10  3612.0  \n",
       "567  https://ssl.pstatic.net/imgstock/upload/resear...  24.05.10  1611.0  \n",
       "568  https://ssl.pstatic.net/imgstock/upload/resear...  24.05.10  1249.0  \n",
       "569  https://ssl.pstatic.net/imgstock/upload/resear...  24.05.10  1042.0  \n",
       "\n",
       "[570 rows x 6 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "7b7e4e7f-3c58-4f70-abc8-db8c10c6713b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "검색할 종목명을 입력하세요:  두올\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 DataFrame 초기화\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# 종목명 입력 받기\n",
    "stock_name = input(\"검색할 종목명을 입력하세요: \")\n",
    "\n",
    "# 페이지 범위를 설정\n",
    "for page in range(1, 40):\n",
    "    url = f'https://finance.naver.com/research/company_list.naver?&page={page}'\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # 첨부 파일 링크 추출\n",
    "    fils = [s['href'] for s in soup.select('td.file a')]\n",
    "\n",
    "    \n",
    "    # 테이블 추출\n",
    "    table = soup.select('table')[0]\n",
    "    table_html = str(table)\n",
    "    table_df = pd.read_html(StringIO(table_html))[0].dropna(how='all')  # NaN값 제거\n",
    "    table_df['첨부'] = fils\n",
    "    \n",
    "    # 종목명에 해당하는 데이터만 추출하여 결과 DataFrame에 추가\n",
    "    filtered_df = table_df[table_df['종목명'].str.contains(stock_name)]\n",
    "    result_df = pd.concat([result_df, filtered_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "461e3d3c-4d86-4b7f-b2ff-a92cbfa6c4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "검색할 종목명을 입력하세요:  롯데쇼핑\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# 결과를 저장할 DataFrame 초기화\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# 종목명 입력 받기\n",
    "stock_name = input(\"검색할 종목명을 입력하세요: \")\n",
    "\n",
    "# 페이지 범위를 설정\n",
    "for page in range(1, 20):\n",
    "    url = f'https://finance.naver.com/research/company_list.naver?&page={page}'\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # 테이블 추출\n",
    "    table = soup.select('table')[0]\n",
    "    table_html = str(table)\n",
    "    table_df = pd.read_html(StringIO(table_html))[0].dropna(how='all')  # NaN값 제거\n",
    "    \n",
    "    # 종목명에 해당하는 데이터만 추출하여 결과 DataFrame에 추가\n",
    "    filtered_df = table_df[table_df['종목명'].str.contains(stock_name)]\n",
    "    result_df = pd.concat([result_df, filtered_df], ignore_index=True)\n",
    "\n",
    "    result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "637b0e41-107e-4895-8517-47c3ab259794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목명</th>\n",
       "      <th>제목</th>\n",
       "      <th>증권사</th>\n",
       "      <th>첨부</th>\n",
       "      <th>작성일</th>\n",
       "      <th>조회수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>롯데쇼핑</td>\n",
       "      <td>1Q24 Review : 해외 사업 성과에 대해 프라이..</td>\n",
       "      <td>한화투자증권</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.05.10</td>\n",
       "      <td>1042.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     종목명                                제목     증권사  첨부       작성일     조회수\n",
       "45  롯데쇼핑  1Q24 Review : 해외 사업 성과에 대해 프라이..  한화투자증권 NaN  24.05.10  1042.0"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4a46a87f-c488-48ed-bd03-452cca81ba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 하이퍼링크와 함께 HTML 파일로 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# 결과를 저장할 DataFrame 초기화\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# 페이지 범위를 설정\n",
    "for page in range(1, 10):\n",
    "    url = f'https://finance.naver.com/research/company_list.naver?&page={page}'\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # 첨부 파일 링크 추출\n",
    "    fils = [s['href'] for s in soup.select('td.file a')]\n",
    "    fils = [f'https://finance.naver.com{s}' for s in fils]  # 절대 경로로 변환\n",
    "    \n",
    "    # 테이블 추출\n",
    "    table = soup.select('table')[0]\n",
    "    table_html = str(table)\n",
    "    table_df = pd.read_html(StringIO(table_html))[0].dropna(how='all')  # NaN값 제거\n",
    "    \n",
    "    # 하이퍼링크 추가\n",
    "    table_df['첨부'] = [f'<a href=\"{link}\" target=\"_blank\">파일 다운로드</a>' for link in fils]\n",
    "    \n",
    "    # 페이지 결과를 누적\n",
    "    result_df = pd.concat([result_df, table_df], ignore_index=True)\n",
    "\n",
    "# HTML 파일로 저장\n",
    "html_result = result_df.to_html(escape=False)\n",
    "\n",
    "with open('result_with_hyperlinks.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(html_result)\n",
    "\n",
    "print(\"데이터가 하이퍼링크와 함께 HTML 파일로 성공적으로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ac82fd13-a786-46d2-a4c2-5a2d99d54ea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3477860531.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[266], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    \\\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "95079a10-b765-440a-8502-f85eed688525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\1258229839.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\1258229839.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\1258229839.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\1258229839.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\1258229839.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\1258229839.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\1258229839.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\1258229839.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 조회순으로 정렬되어 HTML 파일로 성공적으로 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20636\\1258229839.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# 결과를 저장할 DataFrame 초기화\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# 페이지 범위를 설정\n",
    "for page in range(1, 10):\n",
    "    url = f'https://finance.naver.com/research/company_list.naver?&page={page}'\n",
    "    response = requests.get(url)\n",
    "    content = response.content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # 첨부 파일 링크 추출\n",
    "    fils = [s['href'] for s in soup.select('td.file a')]\n",
    "    \n",
    "    # 테이블 추출\n",
    "    table = soup.select('table')[0]\n",
    "    table_df = pd.read_html(str(table))[0].dropna(how='all')  # NaN값 제거\n",
    "    \n",
    "    # 조회수 추출\n",
    "    views = []\n",
    "    for row in soup.select('table tbody tr'):\n",
    "        try:\n",
    "            view = int(row.select('td')[-1].text.replace(',', ''))\n",
    "        except (IndexError, ValueError):\n",
    "            view = 0\n",
    "        views.append(view)\n",
    "    \n",
    "    # 조회수를 데이터프레임에 추가\n",
    "    if views:\n",
    "        table_df['조회수'] = views\n",
    "    else:\n",
    "        table_df['조회수'] = 0\n",
    "    \n",
    "    # 페이지 결과를 누적\n",
    "    result_df = pd.concat([result_df, table_df], ignore_index=True)\n",
    "\n",
    "# 조회수를 기준으로 정렬\n",
    "result_df = result_df.sort_values(by='조회수', ascending=False)\n",
    "\n",
    "# HTML 파일로 저장\n",
    "result_df.to_html('result.html', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"데이터가 조회순으로 정렬되어 HTML 파일로 성공적으로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e23d3a-3093-44d8-9495-13a26270818f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
